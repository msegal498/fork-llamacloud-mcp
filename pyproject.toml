[tool.poetry]
name = "llamacloud-mcp"
version = "0.1.0"
description = "Integration between LlamaCloud and Model Control Protocol (MCP)"
authors = ["max segal <mscp498@gmail.com>"]
readme = "README.md"
packages = [
    { include = "backend" },
    { include = "frontend" }
]

[tool.poetry.dependencies]
python = "^3.11"
llama-index-llms-openai = "^0.3.28"
llama-index-indices-managed-llama-cloud = "^0.6.9"
mcp = "^1.6.0"
python-dotenv = "^1.1.0"
llama-index-tools-mcp = "^0.1.0"
fastapi = "^0.110.0"
uvicorn = "^0.27.0"
httpx = "^0.27.0"
python-multipart = "^0.0.9"
pypdf2 = "^3.0.1"
reportlab = "^4.1.0"
aiofiles = "^23.2.1"

[tool.poetry.dev-dependencies]
pytest = "^7.3.1"
black = "^23.3.0"
isort = "^5.12.0"

[tool.poetry.scripts]
start-mcp-http = "backend.api.mcp_http_server:main"
start-frontend = "frontend.server.frontend_server:main"
start-mcp-server = "backend.llamacloud_mcp.mcp_server:main"
start = "scripts.start_system:main"
test-env = "scripts.test_env:main"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.black]
line-length = 88
target-version = ['py311']

[tool.isort]
profile = "black"
line_length = 88
